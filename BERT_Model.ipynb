{"cells":[{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"id":"sU0FH4YNFe00"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"v-h6VBIK5o4Z"},"outputs":[],"source":["import pandas as pd\n","path=\"/content/drive/MyDrive/b-11 major project/metadata_allvisits.csv\"\n","df = pd.read_csv(path)\n","path1=\"/content/drive/MyDrive/b-11 major project/metadata_allvisitsfluency.csv\"\n","df1 = pd.read_csv(path1)\n","path2=\"/content/drive/MyDrive/b-11 major project/metadata_allvisitsrecall.csv\"\n","df2= pd.read_csv(path2)\n","path3=\"/content/drive/MyDrive/b-11 major project/metadata_allvisitssentence.csv\"\n","df3= pd.read_csv(path3)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Odl6olZN4gJ7"},"outputs":[],"source":["df=pd.concat([df,df1, df2,df3])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"HGF5UtIe4BwM"},"outputs":[],"source":["df['pauses']=df['pause1']+df['pause2']+df['pause3']\n","df=df.drop(['filepath','pause1','pause2','pause3'], axis = 1)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"MoccOQHR4Gsx"},"outputs":[],"source":["df[\"mmse\"].fillna(31, inplace = True)\n","df[\"age\"].fillna(0, inplace = True)\n","df[\"gender\"].fillna(\"other\", inplace = True)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bnDmigNj4Jn5","outputId":"5c16238b-7426-456a-d6fb-1536a67803dd"},"outputs":[{"data":{"text/plain":["array([0, 1], dtype=int64)"]},"execution_count":6,"metadata":{},"output_type":"execute_result"}],"source":["df = df.dropna(axis=0, subset=['category'])\n","df[\"category\"] = df[\"category\"].str.lower()\n","df[\"category\"] = df[\"category\"].replace(to_replace =\"probable\",value =\"probablead\")\n","df[\"category\"] = df[\"category\"].replace(to_replace =[\"probablead\",\"mci\",\"memory\",\"vascular\",\"possiblead\",\"dementia\"],value =1)\n","df[\"category\"] = df[\"category\"].replace(to_replace =[\"control\",\"other\"],value = 0)\n","df.category.unique()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0tgTfLh74Nu2"},"outputs":[],"source":["import string\n","import re\n","import pandas as pd\n","from nltk.stem import SnowballStemmer\n","from nltk.stem import WordNetLemmatizer\n","from nltk.tokenize import word_tokenize"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zhUghLxT4QZD"},"outputs":[],"source":["table = str.maketrans(string.punctuation, ' '*len(string.punctuation))\n","string_punctuation_1 = string.punctuation.replace(\".\",\"\").replace(\"`\",\"\").replace(\"'\",\"\")\n","table_ = str.maketrans(string_punctuation_1, ' '*len(string_punctuation_1))\n","printable = set(string.printable)\n","\n","\n","def clean_data(text):\n","\n","    sentence = text.lower()\n","    sentence_no_punct = sentence.translate(table_)\n","    space_remove = re.sub('\\s+',' ', sentence_no_punct)\n","    return space_remove"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":70},"id":"lz80_NM84TGa","outputId":"f23f8d1c-1434-44bd-cf1e-b693889faf4c"},"outputs":[{"data":{"text/plain":["\" i like to write a note with a pencil . tree the tree is okay in the summertime but i don't like to crawl up in the wintertime . i i visit the child's hospital to see my neighbor the child . i i should have made it a little shorter but cold winter is so far we haven't had a cold winter . it isn't quite a winter yet . chair chairq doctorq and what oh sit in the doctor's chair . open the bureau door . \""]},"execution_count":9,"metadata":{},"output_type":"execute_result"}],"source":["df['Transcripts_cleaned'] = df['data'].apply(lambda row: clean_data(row) )\n","df['Transcripts_cleaned'].iloc[1205]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KK_OUZrF6dsX"},"outputs":[],"source":["stemmer = SnowballStemmer('english')\n","def stem_words(text):\n","    text = text.split()\n","    stemmed_words = [stemmer.stem(word) for word in text]\n","    text = \" \".join(stemmed_words)\n","    return text"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"K7ToBySG6lDD","outputId":"ee61e028-3520-4a9a-9cfb-2533471d5ac3"},"outputs":[{"data":{"text/plain":["0      the scene is in the in the kitchen . the mothe...\n","1      oh i see the sink is run over . i see the stoo...\n","2      a boy and a girl are in the kitchen with their...\n","3      it was summertim and mother and the children w...\n","4      wait until i put my glass on . oh ‡ there a gi...\n","                             ...                        \n","236    pencilq . ‡ well you write with a pencil . wel...\n","237    treeq what is realli amaz me amaz me to me whe...\n","238    write me a letter . oh boy ‡ i'm way out today...\n","239    i write with a pencil . the tree are beauti in...\n","240    she wrote with a pencil . treeq . the tree is ...\n","Name: Transcripts_stem, Length: 1299, dtype: object"]},"execution_count":11,"metadata":{},"output_type":"execute_result"}],"source":["df['Transcripts_stem'] = df['Transcripts_cleaned'].apply(lambda row: stem_words(row))\n","df['Transcripts_stem']"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1c5m3N-MXmVZ","outputId":"d4a06c31-8f4c-4a59-820a-1dab74d2679e"},"outputs":[{"name":"stderr","output_type":"stream","text":["[nltk_data] Error loading popular: <urlopen error [WinError 10060] A\n","[nltk_data]     connection attempt failed because the connected party\n","[nltk_data]     did not properly respond after a period of time, or\n","[nltk_data]     established connection failed because connected host\n","[nltk_data]     has failed to respond>\n"]},{"data":{"text/plain":["False"]},"execution_count":19,"metadata":{},"output_type":"execute_result"}],"source":["# import nltk\n","# nltk.download('punkt')\n","# nltk.download('wordnet')\n","import nltk\n","nltk.download('popular')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"x78WbMiEW3dm","outputId":"9ae68611-6540-4b04-b5f7-ec9499d9010a"},"outputs":[{"ename":"ImportError","evalue":"cannot import name 'punkt' from 'nltk.corpus' (D:\\python\\Lib\\site-packages\\nltk\\corpus\\__init__.py)","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)","Cell \u001b[1;32mIn[16], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnltk\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcorpus\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m punkt\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnltk\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcorpus\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m wordnet\n\u001b[0;32m      3\u001b[0m lemmatizer \u001b[38;5;241m=\u001b[39m wordnet\u001b[38;5;241m.\u001b[39mWordNetLemmatizer()\n","\u001b[1;31mImportError\u001b[0m: cannot import name 'punkt' from 'nltk.corpus' (D:\\python\\Lib\\site-packages\\nltk\\corpus\\__init__.py)"]}],"source":["lemmatizer = WordNetLemmatizer()\n","\n","df['Transcripts_lem'] = df['Transcripts_cleaned'].apply(lambda row: \" \".join([lemmatizer.lemmatize(i) for i in word_tokenize(row)]))\n","\n","df['Transcripts_lem']"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vhgoY5ko6rTY"},"outputs":[],"source":["# df[\"labels\"] = df[\"category\"].astype('category')\n","# df.dtypes\n","# df[\"AD\"] = df[\"labels\"].cat.codes\n","# df.labels.unique()\n","# df[\"category\"] = df[\"category\"].replace(to_replace =[\"probablead\",\"mci\",\"memory\",\"vascular\",\"possiblead\",\"dementia\"],value =1)\n","# df[\"category\"] = df[\"category\"].replace(to_replace =[\"control\",\"other\"],value = 0)\n","df.to_csv('/content/drive/MyDrive/Major Project stuff/metadata.csv')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3IFMIjBZdo9e"},"outputs":[],"source":["import pandas as pd\n","df=pd.read_csv('/content/drive/MyDrive/Major Project stuff/metadata.csv')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Dic-8XvnLdTC"},"outputs":[],"source":["df"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"yCRiYOoRderM"},"outputs":[],"source":["!pip install transformers"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"db5GAUTDeLmE"},"outputs":[],"source":["!pip install pytorch-pretrained-bert"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"BMAFT4ZU6xdE"},"outputs":[],"source":["from transformers import BertTokenizer\n","\n","print('Loading BERT tokenizer...')\n","tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"M8slQpK060B9"},"outputs":[],"source":["sentences = df['Transcripts_lem'].values\n","labels = df.category.values"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"VyOC0K6d62hu"},"outputs":[],"source":["max_len = 0\n","\n","for sent in sentences:\n","    input_ids = tokenizer.encode(sent, add_special_tokens=True,max_length=256)\n","    max_len = max(max_len, len(input_ids))\n","\n","print('Max sentence length: ', max_len)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mER5ov2B66bQ"},"outputs":[],"source":["import tensorflow as tf\n","import torch"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7jAtPUK868tb"},"outputs":[],"source":["input_ids = []\n","attention_masks = []\n","\n","for sent in sentences:\n","    encoded_dict = tokenizer.encode_plus(\n","                        sent,\n","                        add_special_tokens = True,\n","                        max_length = 256,\n","                        pad_to_max_length = True,\n","                        return_attention_mask = True,\n","                        return_tensors = 'pt',\n","                   )\n","    input_ids.append(encoded_dict['input_ids'])\n","    attention_masks.append(encoded_dict['attention_mask'])\n","\n","input_ids = torch.cat(input_ids, dim=0)\n","attention_masks = torch.cat(attention_masks, dim=0)\n","labels = torch.tensor(labels)\n","\n","print('Original: ', sentences[0])\n","print('Token IDs:', input_ids[0])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KBR8AwVNOQCw"},"outputs":[],"source":["print(input_ids.shape)\n","print(attention_masks.shape)\n","print(labels.shape)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vEzpBJRW7J0_"},"outputs":[],"source":["from torch.utils.data import TensorDataset, random_split\n","\n","dataset = TensorDataset(input_ids, attention_masks, labels)\n","\n","train_size = int(0.8 * len(dataset))\n","val_size = int(0.1 * len(dataset))\n","test_size = len(dataset) - train_size - val_size\n","\n","train_dataset, val_dataset, test_dataset = random_split(dataset, [train_size, val_size,test_size])\n","\n","print('{:>5,} training samples'.format(train_size))\n","print('{:>5,} validation samples'.format(val_size))\n","print('{:>5,} test samples'.format(test_size))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cIAl5MRo7NJz"},"outputs":[],"source":["from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n","\n","batch_size = 32\n","\n","train_dataloader = DataLoader(\n","            train_dataset,\n","            sampler = RandomSampler(train_dataset),\n","            batch_size = batch_size\n","        )\n","\n","validation_dataloader = DataLoader(\n","            val_dataset,\n","            sampler = SequentialSampler(val_dataset),\n","            batch_size = batch_size\n","        )\n","test_dataloader = DataLoader(\n","            test_dataset,\n","            sampler = SequentialSampler(test_dataset),\n","            batch_size = batch_size\n","        )"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7WR5JD7H7TSX"},"outputs":[],"source":["from transformers import BertForSequenceClassification, AdamW, BertConfig\n","\n","model = BertForSequenceClassification.from_pretrained(\n","    \"bert-base-uncased\",\n","    num_labels = 2,\n","    output_attentions = False,\n","    output_hidden_states = False,\n",")\n","\n","# Tell pytorch to run this model on the GPU.\n","model.cuda()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"DR6SV5Sp-xbu"},"outputs":[],"source":["params = list(model.named_parameters())\n","\n","print('The BERT model has {:} different named parameters.\\n'.format(len(params)))\n","\n","print('==== Embedding Layer ====\\n')\n","\n","for p in params[0:5]:\n","    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n","\n","print('\\n==== First Transformer ====\\n')\n","\n","for p in params[5:21]:\n","    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n","\n","print('\\n==== Output Layer ====\\n')\n","\n","for p in params[-4:]:\n","    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"uA07gq5B-2uj"},"outputs":[],"source":["optimizer = AdamW(model.parameters(),\n","                  lr = 2e-5,\n","                  eps = 1e-8\n","                )"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZtsD0xzn-6mk"},"outputs":[],"source":["from transformers import get_linear_schedule_with_warmup\n","\n","epochs = 4\n","\n","total_steps = len(train_dataloader) * epochs\n","\n","# Create the learning rate scheduler.\n","scheduler = get_linear_schedule_with_warmup(optimizer,\n","                                            num_warmup_steps = 0, # Default value in run_glue.py\n","                                            num_training_steps = total_steps)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"eNSzS5gT_H3W"},"outputs":[],"source":["import numpy as np\n","\n","# Function to calculate the accuracy of our predictions vs labels\n","def flat_accuracy(preds, labels):\n","    pred_flat = np.argmax(preds, axis=1).flatten()\n","    labels_flat = labels.flatten()\n","    return np.sum(pred_flat == labels_flat) / len(labels_flat)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gTgyYBUc_LFg"},"outputs":[],"source":["import time\n","import datetime\n","\n","def format_time(elapsed):\n","    '''\n","    Takes a time in seconds and returns a string hh:mm:ss\n","    '''\n","    # Round to the nearest second.\n","    elapsed_rounded = int(round((elapsed)))\n","\n","    # Format as hh:mm:ss\n","    return str(datetime.timedelta(seconds=elapsed_rounded))\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"JZ7zOpV2_OEM"},"outputs":[],"source":["device = torch.device(\"cuda\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"MwbFQJ35_XZA"},"outputs":[],"source":["import random\n","import numpy as np\n","\n","# Setting the seed value all over the place to make this reproducible.\n","seed_val = 42\n","\n","random.seed(seed_val)\n","np.random.seed(seed_val)\n","torch.manual_seed(seed_val)\n","torch.cuda.manual_seed_all(seed_val)\n","\n","\n","training_stats = []\n","total_t0 = time.time()\n","\n","# For each epoch...\n","for epoch_i in range(0, epochs):\n","\n","    # ========================================\n","    #               Training\n","    # ========================================\n","\n","    print(\"\")\n","    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n","    print('Training...')\n","\n","    t0 = time.time()\n","    total_train_loss = 0\n","\n","    # Put the model into training mode.\n","    model.train()\n","\n","    # For each batch of training data...\n","    for step, batch in enumerate(train_dataloader):\n","\n","        # Progress update every 40 batches.\n","        if step % 40 == 0 and not step == 0:\n","            elapsed = format_time(time.time() - t0)\n","            print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n","\n","        # Unpacking this training batch from our dataloader.\n","        # `batch` contains three pytorch tensors:\n","        #   [0]: input ids\n","        #   [1]: attention masks\n","        #   [2]: labels\n","        b_input_ids = batch[0].to(device)\n","        b_input_mask = batch[1].to(device)\n","        b_labels = batch[2].to(device)\n","\n","        model.zero_grad()\n","\n","        # Performing a forward pass (evaluate the model on this training batch).\n","        outputs = model(b_input_ids,\n","                             token_type_ids=None,\n","                             attention_mask=b_input_mask,\n","                             labels=b_labels)\n","        loss=outputs[0]\n","\n","        # Accumulating the training loss over all of the batches so that we can\n","        total_train_loss += loss.item()\n","\n","        # Performing a backward pass to calculate the gradients.\n","        loss.backward()\n","\n","        # Clipping the norm of the gradients to 1.0.\n","        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n","\n","        optimizer.step()\n","\n","        # Updating the learning rate.\n","        scheduler.step()\n","\n","    # Calculating the average loss over all of the batches.\n","    avg_train_loss = total_train_loss / len(train_dataloader)\n","\n","    # Measuring how long this epoch took.\n","    training_time = format_time(time.time() - t0)\n","\n","    print(\"\")\n","    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n","    print(\"  Training epcoh took: {:}\".format(training_time))\n","\n","    # ========================================\n","    #               Validation\n","    # ========================================\n","\n","    print(\"\")\n","    print(\"Running Validation...\")\n","\n","    t0 = time.time()\n","\n","    # Put the model in evaluation mode\n","    model.eval()\n","\n","    total_eval_accuracy = 0\n","    total_eval_loss = 0\n","    nb_eval_steps = 0\n","\n","    for batch in validation_dataloader:\n","\n","        b_input_ids = batch[0].to(device)\n","        b_input_mask = batch[1].to(device)\n","        b_labels = batch[2].to(device)\n","\n","        with torch.no_grad():\n","\n","            # Forward pass, calculating logit predictions.\n","            outputs = model(b_input_ids,\n","                                   token_type_ids=None,\n","                                   attention_mask=b_input_mask,\n","                                   labels=b_labels)\n","        loss=outputs[0]\n","\n","        # Accumulating the validation loss.\n","        total_eval_loss += loss.item()\n","\n","        logits=outputs[1]\n","        # Moving logits and labels to CPU\n","        logits = logits.detach().cpu().numpy()\n","        label_ids = b_labels.to('cpu').numpy()\n","\n","        # Calculating the accuracy for this batch of test sentences, and accumulate it over all batches.\n","        total_eval_accuracy += flat_accuracy(logits, label_ids)\n","\n","\n","    # Reporting the final accuracy for this validation run.\n","    avg_val_accuracy = total_eval_accuracy / len(validation_dataloader)\n","    print(\"  Accuracy: {0:.2f}\".format(avg_val_accuracy))\n","\n","    # Calculating the average loss over all of the batches.\n","    avg_val_loss = total_eval_loss / len(validation_dataloader)\n","\n","    # Measuring how long the validation run took.\n","    validation_time = format_time(time.time() - t0)\n","\n","    print(\"  Validation Loss: {0:.2f}\".format(avg_val_loss))\n","    print(\"  Validation took: {:}\".format(validation_time))\n","\n","    # Recording all statistics from this epoch.\n","    training_stats.append(\n","        {\n","            'epoch': epoch_i + 1,\n","            'Training Loss': avg_train_loss,\n","            'Valid. Loss': avg_val_loss,\n","            'Valid. Accur.': avg_val_accuracy,\n","            'Training Time': training_time,\n","            'Validation Time': validation_time\n","        }\n","    )\n","\n","print(\"\")\n","print(\"Training complete!\")\n","\n","print(\"Total training took {:} (h:mm:ss)\".format(format_time(time.time()-total_t0)))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"p3hjBE3WcS4K"},"outputs":[],"source":["import pandas as pd\n","\n","pd.set_option('precision', 6)\n","\n","df_stats = pd.DataFrame(data=training_stats)\n","\n","df_stats = df_stats.set_index('epoch')\n","\n","df_stats"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"niCVHea_cay0"},"outputs":[],"source":["import matplotlib.pyplot as plt\n","% matplotlib inline\n","\n","import seaborn as sns\n","\n","sns.set(style='ticks')\n","\n","sns.set(font_scale=1.5)\n","plt.rcParams[\"figure.figsize\"] = (12,6)\n","\n","plt.plot(df_stats['Training Loss'], 'b', label=\"Training\")\n","plt.plot(df_stats['Valid. Loss'], 'g', label=\"Validation\")\n","\n","plt.title(\"Training & Validation Loss\")\n","plt.xlabel(\"Epoch\")\n","plt.ylabel(\"Loss\")\n","plt.legend()\n","plt.xticks([1, 2, 3, 4])\n","\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hJc5Up6pclXB"},"outputs":[],"source":["import matplotlib.pyplot as plt\n","% matplotlib inline\n","\n","import seaborn as sns\n","\n","sns.set(style='darkgrid')\n","\n","sns.set(font_scale=1.5)\n","plt.rcParams[\"figure.figsize\"] = (12,6)\n","\n","plt.plot(df_stats['Valid. Accur.'], 'b', label=\"Validation_acc\")\n","plt.plot(df_stats['Valid. Loss'], 'g', label=\"Validation_loss\")\n","\n","plt.title(\"Validation accuracy & Validation Loss\")\n","plt.xlabel(\"Epoch\")\n","plt.ylabel(\"Loss\")\n","plt.legend()\n","plt.xticks([1, 2, 3, 4])\n","\n","plt.show()\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"unF57nMycr9S"},"outputs":[],"source":["import torch.nn.functional as F\n","# Put model in evaluation mode\n","model.eval()\n","\n","predictions , true_labels = [], []\n","prediction_probs = []\n","for batch in test_dataloader:\n","  batch = tuple(t.to(device) for t in batch)\n","\n","  b_input_ids, b_input_mask, b_labels = batch\n","\n","  with torch.no_grad():\n","      outputs = model(b_input_ids, token_type_ids=None,\n","                      attention_mask=b_input_mask)\n","\n","  _, preds = torch.max(outputs[0], dim=1)\n","  logits = outputs[0]\n","  predictions.extend(preds)\n","  prediction_probs.extend(outputs[0])\n","\n","  logits = logits.detach().cpu().numpy()\n","\n","  #predictions.append(logits)\n","  true_labels.extend(b_labels)\n","predictions = torch.stack(predictions).cpu()\n","prediction_probs = torch.stack(prediction_probs).cpu()\n","true_labels = torch.stack(true_labels).cpu()\n","\n","print('    DONE.')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"K-Fp9pnUcv7O"},"outputs":[],"source":["true_labels"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"l_sNkwL2c0x_"},"outputs":[],"source":["from sklearn.metrics import confusion_matrix\n","from sklearn.metrics import accuracy_score, log_loss\n","from sklearn.metrics import precision_recall_fscore_support, classification_report\n","from sklearn.metrics import roc_curve , roc_auc_score, auc\n","\n","def evaluate_roc(probs, y_true):\n","    \"\"\"\n","    - Print AUC and accuracy on the test set\n","    - Plot ROC\n","    @params    probs (np.array): an array of predicted probabilities with shape (len(y_true), 2)\n","    @params    y_true (np.array): an array of the true values with shape (len(y_true),)\n","    \"\"\"\n","    preds = probs[:, 1]\n","    fpr, tpr, threshold = roc_curve(y_true, preds)\n","    roc_auc = auc(fpr, tpr)\n","    print(f'AUC: {roc_auc:.4f}')\n","\n","    y_pred = np.where(preds >= 0.5, 1, 0)\n","    accuracy = accuracy_score(y_true, y_pred)\n","    print(f'Accuracy: {accuracy*100:.2f}%')\n","\n","\n","    plt.title('Receiver Operating Characteristic')\n","    plt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)\n","    plt.legend(loc = 'lower right')\n","    plt.plot([0, 1], [0, 1],'r--')\n","    plt.xlim([0, 1])\n","    plt.ylim([0, 1])\n","    plt.ylabel('True Positive Rate')\n","    plt.xlabel('False Positive Rate')\n","    plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"TkjjRDtvc4K9"},"outputs":[],"source":["evaluate_roc(prediction_probs , true_labels)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"PGxCE6oDggNv"},"outputs":[],"source":["from sklearn.metrics import confusion_matrix\n","from sklearn.metrics import accuracy_score, log_loss\n","from sklearn.metrics import precision_recall_fscore_support, classification_report\n","from sklearn.metrics import roc_curve , roc_auc_score\n","\n","\n","labels = [0, 1]\n","print(accuracy_score(true_labels, predictions))\n","print(confusion_matrix(true_labels, predictions))\n","# print(precision_recall_fscore_support(true_labels, predictions, average=None, labels= labels))\n","print(classification_report(true_labels, predictions))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"YrWeDT3GFT-y"},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.3"}},"nbformat":4,"nbformat_minor":0}