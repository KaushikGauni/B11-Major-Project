{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1qBVNz9zd6T2GEH7mXG869FJpJJxSPTxF","timestamp":1711885973281}]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gWxZXMGSAUj1","executionInfo":{"status":"ok","timestamp":1711885907717,"user_tz":-330,"elapsed":4258,"user":{"displayName":"Kaushik Gauni","userId":"05737776589038746840"}},"outputId":"92a6d669-6e79-42a3-f0f1-b9457de36c8d"},"execution_count":369,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"code","metadata":{"id":"v-h6VBIK5o4Z","executionInfo":{"status":"ok","timestamp":1711885907718,"user_tz":-330,"elapsed":33,"user":{"displayName":"Kaushik Gauni","userId":"05737776589038746840"}}},"source":["import pandas as pd\n","path=\"/content/drive/MyDrive/b-11 major project/BERT/metadata_allvisits.csv\"\n","df = pd.read_csv(path)\n","path1=\"/content/drive/MyDrive/b-11 major project/BERT/metadata_allvisitsfluency.csv\"\n","df1 = pd.read_csv(path1)\n","path2=\"/content/drive/MyDrive/b-11 major project/BERT/metadata_allvisitsrecall.csv\"\n","df2= pd.read_csv(path2)\n","path3=\"/content/drive/MyDrive/b-11 major project/BERT/metadata_allvisitssentence.csv\"\n","df3= pd.read_csv(path3)"],"execution_count":370,"outputs":[]},{"cell_type":"code","metadata":{"id":"Odl6olZN4gJ7","executionInfo":{"status":"ok","timestamp":1711885907719,"user_tz":-330,"elapsed":31,"user":{"displayName":"Kaushik Gauni","userId":"05737776589038746840"}}},"source":["dataFrame=pd.concat([df,df1, df2,df3])"],"execution_count":371,"outputs":[]},{"cell_type":"code","metadata":{"id":"HGF5UtIe4BwM","executionInfo":{"status":"ok","timestamp":1711885907720,"user_tz":-330,"elapsed":31,"user":{"displayName":"Kaushik Gauni","userId":"05737776589038746840"}}},"source":["dataFrame['pauses']=dataFrame['pause1']+dataFrame['pause2']+dataFrame['pause3']\n","df=dataFrame.drop(['filepath','pause1','pause2','pause3'], axis = 1)"],"execution_count":372,"outputs":[]},{"cell_type":"code","metadata":{"id":"MoccOQHR4Gsx","executionInfo":{"status":"ok","timestamp":1711885907720,"user_tz":-330,"elapsed":30,"user":{"displayName":"Kaushik Gauni","userId":"05737776589038746840"}}},"source":["df[\"mmse\"].fillna(31, inplace = True)\n","df[\"age\"].fillna(0, inplace = True)\n","df[\"gender\"].fillna(\"other\", inplace = True)"],"execution_count":373,"outputs":[]},{"cell_type":"code","metadata":{"id":"bnDmigNj4Jn5","colab":{"base_uri":"https://localhost:8080/"},"outputId":"75296c89-0c8c-437c-8b2d-91e3d59e297d","executionInfo":{"status":"ok","timestamp":1711885907720,"user_tz":-330,"elapsed":29,"user":{"displayName":"Kaushik Gauni","userId":"05737776589038746840"}}},"source":["df = df.dropna(axis=0, subset=['category'])\n","df[\"category\"] = df[\"category\"].str.lower()\n","df[\"category\"] = df[\"category\"].replace(to_replace =\"probable\",value =\"probablead\")\n","df[\"category\"] = df[\"category\"].replace(to_replace =[\"probablead\",\"mci\",\"memory\",\"vascular\",\"possiblead\",\"dementia\"],value =1)\n","df[\"category\"] = df[\"category\"].replace(to_replace =[\"control\",\"other\"],value = 0)\n","df.category.unique()"],"execution_count":374,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([0, 1])"]},"metadata":{},"execution_count":374}]},{"cell_type":"code","metadata":{"id":"0tgTfLh74Nu2","executionInfo":{"status":"ok","timestamp":1711885907721,"user_tz":-330,"elapsed":26,"user":{"displayName":"Kaushik Gauni","userId":"05737776589038746840"}}},"source":["import string\n","import re\n","import pandas as pd\n","from nltk.stem import SnowballStemmer\n","from nltk.stem import WordNetLemmatizer\n","from nltk.tokenize import word_tokenize"],"execution_count":375,"outputs":[]},{"cell_type":"code","metadata":{"id":"zhUghLxT4QZD","executionInfo":{"status":"ok","timestamp":1711885907721,"user_tz":-330,"elapsed":24,"user":{"displayName":"Kaushik Gauni","userId":"05737776589038746840"}}},"source":["table = str.maketrans(string.punctuation, ' '*len(string.punctuation))\n","string_punctuation_1 = string.punctuation.replace(\".\",\"\").replace(\"`\",\"\").replace(\"'\",\"\")\n","table_ = str.maketrans(string_punctuation_1, ' '*len(string_punctuation_1))\n","printable = set(string.printable)\n","\n","\n","def clean_data(text):\n","\n","    sentence = text.lower()\n","    sentence_no_punct = sentence.translate(table_)\n","    space_remove = re.sub('\\s+',' ', sentence_no_punct)\n","    return space_remove"],"execution_count":376,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":70},"id":"lz80_NM84TGa","outputId":"16052215-9810-4ff4-dbb0-ab378860f9f2","executionInfo":{"status":"ok","timestamp":1711885907722,"user_tz":-330,"elapsed":24,"user":{"displayName":"Kaushik Gauni","userId":"05737776589038746840"}}},"source":["df['Transcripts_cleaned'] = df['data'].apply(lambda row: clean_data(row) )\n","df['Transcripts_cleaned'].iloc[1205]"],"execution_count":377,"outputs":[{"output_type":"execute_result","data":{"text/plain":["\" i like to write a note with a pencil . tree the tree is okay in the summertime but i don't like to crawl up in the wintertime . i i visit the child's hospital to see my neighbor the child . i i should have made it a little shorter but cold winter is so far we haven't had a cold winter . it isn't quite a winter yet . chair chairq doctorq and what oh sit in the doctor's chair . open the bureau door . \""],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":377}]},{"cell_type":"code","metadata":{"id":"KK_OUZrF6dsX","executionInfo":{"status":"ok","timestamp":1711885907722,"user_tz":-330,"elapsed":21,"user":{"displayName":"Kaushik Gauni","userId":"05737776589038746840"}}},"source":["stemmer = SnowballStemmer('english')\n","def stem_words(text):\n","    text = text.split()\n","    stemmed_words = [stemmer.stem(word) for word in text]\n","    text = \" \".join(stemmed_words)\n","    return text"],"execution_count":378,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"K7ToBySG6lDD","outputId":"9e8fa5d6-aaa4-4e8b-e0ea-5ac616896a06","executionInfo":{"status":"ok","timestamp":1711885908597,"user_tz":-330,"elapsed":895,"user":{"displayName":"Kaushik Gauni","userId":"05737776589038746840"}}},"source":["df['Transcripts_stem'] = df['Transcripts_cleaned'].apply(lambda row: stem_words(row))\n","df['Transcripts_stem']"],"execution_count":379,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0      the scene is in the in the kitchen . the mothe...\n","1      oh i see the sink is run over . i see the stoo...\n","2      a boy and a girl are in the kitchen with their...\n","3      it was summertim and mother and the children w...\n","4      wait until i put my glass on . oh ‡ there a gi...\n","                             ...                        \n","236    pencilq . ‡ well you write with a pencil . wel...\n","237    treeq what is realli amaz me amaz me to me whe...\n","238    write me a letter . oh boy ‡ i'm way out today...\n","239    i write with a pencil . the tree are beauti in...\n","240    she wrote with a pencil . treeq . the tree is ...\n","Name: Transcripts_stem, Length: 1299, dtype: object"]},"metadata":{},"execution_count":379}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1c5m3N-MXmVZ","outputId":"59317756-5356-4b8a-81e0-7b376b14c468","executionInfo":{"status":"ok","timestamp":1711885908597,"user_tz":-330,"elapsed":10,"user":{"displayName":"Kaushik Gauni","userId":"05737776589038746840"}}},"source":["import nltk\n","nltk.download('punkt')\n","nltk.download('wordnet')"],"execution_count":380,"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Package punkt is already up-to-date!\n","[nltk_data] Downloading package wordnet to /root/nltk_data...\n","[nltk_data]   Package wordnet is already up-to-date!\n"]},{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{},"execution_count":380}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"x78WbMiEW3dm","outputId":"0cf9693c-8fb9-404f-e06e-0a0c8074e3c1","executionInfo":{"status":"ok","timestamp":1711885910143,"user_tz":-330,"elapsed":1551,"user":{"displayName":"Kaushik Gauni","userId":"05737776589038746840"}}},"source":["lemmatizer = WordNetLemmatizer()\n","\n","df['Transcripts_lem'] = df['Transcripts_cleaned'].apply(lambda row: \" \".join([lemmatizer.lemmatize(i) for i in word_tokenize(row)]))\n","\n","df['Transcripts_lem']"],"execution_count":381,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0      the scene is in the in the kitchen . the mothe...\n","1      oh i see the sink is running over . i see the ...\n","2      a boy and a girl are in the kitchen with their...\n","3      it wa summertime and mother and the child were...\n","4      wait until i put my glass on . oh ‡ there 's a...\n","                             ...                        \n","236    pencilq . ‡ well you write with a pencil . wel...\n","237    treeq what is really amazing me amazing me to ...\n","238    write me a letter . oh boy ‡ i 'm way out toda...\n","239    i write with a pencil . the tree are beautiful...\n","240    she wrote with a pencil . treeq . the tree is ...\n","Name: Transcripts_lem, Length: 1299, dtype: object"]},"metadata":{},"execution_count":381}]},{"cell_type":"code","metadata":{"id":"vhgoY5ko6rTY","executionInfo":{"status":"ok","timestamp":1711885910983,"user_tz":-330,"elapsed":845,"user":{"displayName":"Kaushik Gauni","userId":"05737776589038746840"}}},"source":["# df[\"labels\"] = df[\"category\"].astype('category')\n","# df.dtypes\n","# df[\"AD\"] = df[\"labels\"].cat.codes\n","# df.labels.unique()\n","# df[\"category\"] = df[\"category\"].replace(to_replace =[\"probablead\",\"mci\",\"memory\",\"vascular\",\"possiblead\",\"dementia\"],value =1)\n","# df[\"category\"] = df[\"category\"].replace(to_replace =[\"control\",\"other\"],value = 0)\n","df.to_csv('/content/drive/MyDrive/b-11 major project/BERT/metadata.csv')"],"execution_count":382,"outputs":[]},{"cell_type":"code","metadata":{"id":"3IFMIjBZdo9e","executionInfo":{"status":"ok","timestamp":1711885910983,"user_tz":-330,"elapsed":14,"user":{"displayName":"Kaushik Gauni","userId":"05737776589038746840"}}},"source":["import pandas as pd\n","df=pd.read_csv('/content/drive/MyDrive/b-11 major project/BERT/metadata.csv')"],"execution_count":383,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"Dic-8XvnLdTC","outputId":"bc5e1df1-1233-48d8-ae12-1fc8d9132513","executionInfo":{"status":"ok","timestamp":1711885910983,"user_tz":-330,"elapsed":13,"user":{"displayName":"Kaushik Gauni","userId":"05737776589038746840"}}},"source":["df"],"execution_count":384,"outputs":[{"output_type":"execute_result","data":{"text/plain":["      Unnamed: 0   age  gender  mmse  count_unintelligible  count_trailing  \\\n","0              0  58.0  female  30.0                     0               0   \n","1              1  59.0  female  30.0                     1               0   \n","2              2  60.0  female  30.0                     0               0   \n","3              3  61.0  female  28.0                     0               0   \n","4              4  72.0    male  31.0                     0               0   \n","...          ...   ...     ...   ...                   ...             ...   \n","1294         236  73.0  female  13.0                     1               1   \n","1295         237  50.0    male  23.0                     0               0   \n","1296         238  71.0  female  13.0                     1               1   \n","1297         239  74.0  female  21.0                     0               0   \n","1298         240  77.0    male  25.0                     0               2   \n","\n","      count_repetitions  category  \\\n","0                     2         0   \n","1                     0         0   \n","2                     1         0   \n","3                     1         0   \n","4                     0         0   \n","...                 ...       ...   \n","1294                  0         1   \n","1295                  3         0   \n","1296                  2         1   \n","1297                  0         1   \n","1298                  0         1   \n","\n","                                                   data  pauses  \\\n","0      the scene is in the in the kitchen . the moth...       0   \n","1      oh I see the sink is running over . I see the...       0   \n","2      a boy and a girl are in the kitchen with thei...       0   \n","3       it was summertime and mother and the childre...       0   \n","4      wait until I put my glasses on . oh ‡ there's...       0   \n","...                                                 ...     ...   \n","1294   pencilq .  ‡ well you write with a pencil . w...       4   \n","1295   treeq ?  what is really amazing me amazing me...       3   \n","1296   write me a letter . oh   boy ‡ I'm way out to...       5   \n","1297   I write with a pencil . the trees are beautif...       1   \n","1298   she wrote with a pencil .  treeq . the tree i...       0   \n","\n","                                    Transcripts_cleaned  \\\n","0      the scene is in the in the kitchen . the moth...   \n","1      oh i see the sink is running over . i see the...   \n","2      a boy and a girl are in the kitchen with thei...   \n","3      it was summertime and mother and the children...   \n","4      wait until i put my glasses on . oh ‡ there's...   \n","...                                                 ...   \n","1294   pencilq . ‡ well you write with a pencil . we...   \n","1295   treeq what is really amazing me amazing me to...   \n","1296   write me a letter . oh boy ‡ i'm way out toda...   \n","1297   i write with a pencil . the trees are beautif...   \n","1298   she wrote with a pencil . treeq . the tree is...   \n","\n","                                       Transcripts_stem  \\\n","0     the scene is in the in the kitchen . the mothe...   \n","1     oh i see the sink is run over . i see the stoo...   \n","2     a boy and a girl are in the kitchen with their...   \n","3     it was summertim and mother and the children w...   \n","4     wait until i put my glass on . oh ‡ there a gi...   \n","...                                                 ...   \n","1294  pencilq . ‡ well you write with a pencil . wel...   \n","1295  treeq what is realli amaz me amaz me to me whe...   \n","1296  write me a letter . oh boy ‡ i'm way out today...   \n","1297  i write with a pencil . the tree are beauti in...   \n","1298  she wrote with a pencil . treeq . the tree is ...   \n","\n","                                        Transcripts_lem  \n","0     the scene is in the in the kitchen . the mothe...  \n","1     oh i see the sink is running over . i see the ...  \n","2     a boy and a girl are in the kitchen with their...  \n","3     it wa summertime and mother and the child were...  \n","4     wait until i put my glass on . oh ‡ there 's a...  \n","...                                                 ...  \n","1294  pencilq . ‡ well you write with a pencil . wel...  \n","1295  treeq what is really amazing me amazing me to ...  \n","1296  write me a letter . oh boy ‡ i 'm way out toda...  \n","1297  i write with a pencil . the tree are beautiful...  \n","1298  she wrote with a pencil . treeq . the tree is ...  \n","\n","[1299 rows x 13 columns]"],"text/html":["\n","  <div id=\"df-5ab72051-fe7d-44b4-8be2-5720c68bf929\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Unnamed: 0</th>\n","      <th>age</th>\n","      <th>gender</th>\n","      <th>mmse</th>\n","      <th>count_unintelligible</th>\n","      <th>count_trailing</th>\n","      <th>count_repetitions</th>\n","      <th>category</th>\n","      <th>data</th>\n","      <th>pauses</th>\n","      <th>Transcripts_cleaned</th>\n","      <th>Transcripts_stem</th>\n","      <th>Transcripts_lem</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>58.0</td>\n","      <td>female</td>\n","      <td>30.0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>2</td>\n","      <td>0</td>\n","      <td>the scene is in the in the kitchen . the moth...</td>\n","      <td>0</td>\n","      <td>the scene is in the in the kitchen . the moth...</td>\n","      <td>the scene is in the in the kitchen . the mothe...</td>\n","      <td>the scene is in the in the kitchen . the mothe...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>59.0</td>\n","      <td>female</td>\n","      <td>30.0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>oh I see the sink is running over . I see the...</td>\n","      <td>0</td>\n","      <td>oh i see the sink is running over . i see the...</td>\n","      <td>oh i see the sink is run over . i see the stoo...</td>\n","      <td>oh i see the sink is running over . i see the ...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2</td>\n","      <td>60.0</td>\n","      <td>female</td>\n","      <td>30.0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>a boy and a girl are in the kitchen with thei...</td>\n","      <td>0</td>\n","      <td>a boy and a girl are in the kitchen with thei...</td>\n","      <td>a boy and a girl are in the kitchen with their...</td>\n","      <td>a boy and a girl are in the kitchen with their...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>3</td>\n","      <td>61.0</td>\n","      <td>female</td>\n","      <td>28.0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>it was summertime and mother and the childre...</td>\n","      <td>0</td>\n","      <td>it was summertime and mother and the children...</td>\n","      <td>it was summertim and mother and the children w...</td>\n","      <td>it wa summertime and mother and the child were...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>4</td>\n","      <td>72.0</td>\n","      <td>male</td>\n","      <td>31.0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>wait until I put my glasses on . oh ‡ there's...</td>\n","      <td>0</td>\n","      <td>wait until i put my glasses on . oh ‡ there's...</td>\n","      <td>wait until i put my glass on . oh ‡ there a gi...</td>\n","      <td>wait until i put my glass on . oh ‡ there 's a...</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>1294</th>\n","      <td>236</td>\n","      <td>73.0</td>\n","      <td>female</td>\n","      <td>13.0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>pencilq .  ‡ well you write with a pencil . w...</td>\n","      <td>4</td>\n","      <td>pencilq . ‡ well you write with a pencil . we...</td>\n","      <td>pencilq . ‡ well you write with a pencil . wel...</td>\n","      <td>pencilq . ‡ well you write with a pencil . wel...</td>\n","    </tr>\n","    <tr>\n","      <th>1295</th>\n","      <td>237</td>\n","      <td>50.0</td>\n","      <td>male</td>\n","      <td>23.0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>3</td>\n","      <td>0</td>\n","      <td>treeq ?  what is really amazing me amazing me...</td>\n","      <td>3</td>\n","      <td>treeq what is really amazing me amazing me to...</td>\n","      <td>treeq what is realli amaz me amaz me to me whe...</td>\n","      <td>treeq what is really amazing me amazing me to ...</td>\n","    </tr>\n","    <tr>\n","      <th>1296</th>\n","      <td>238</td>\n","      <td>71.0</td>\n","      <td>female</td>\n","      <td>13.0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>write me a letter . oh   boy ‡ I'm way out to...</td>\n","      <td>5</td>\n","      <td>write me a letter . oh boy ‡ i'm way out toda...</td>\n","      <td>write me a letter . oh boy ‡ i'm way out today...</td>\n","      <td>write me a letter . oh boy ‡ i 'm way out toda...</td>\n","    </tr>\n","    <tr>\n","      <th>1297</th>\n","      <td>239</td>\n","      <td>74.0</td>\n","      <td>female</td>\n","      <td>21.0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>I write with a pencil . the trees are beautif...</td>\n","      <td>1</td>\n","      <td>i write with a pencil . the trees are beautif...</td>\n","      <td>i write with a pencil . the tree are beauti in...</td>\n","      <td>i write with a pencil . the tree are beautiful...</td>\n","    </tr>\n","    <tr>\n","      <th>1298</th>\n","      <td>240</td>\n","      <td>77.0</td>\n","      <td>male</td>\n","      <td>25.0</td>\n","      <td>0</td>\n","      <td>2</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>she wrote with a pencil .  treeq . the tree i...</td>\n","      <td>0</td>\n","      <td>she wrote with a pencil . treeq . the tree is...</td>\n","      <td>she wrote with a pencil . treeq . the tree is ...</td>\n","      <td>she wrote with a pencil . treeq . the tree is ...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>1299 rows × 13 columns</p>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5ab72051-fe7d-44b4-8be2-5720c68bf929')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-5ab72051-fe7d-44b4-8be2-5720c68bf929 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-5ab72051-fe7d-44b4-8be2-5720c68bf929');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-3733308c-b6f6-49a1-903a-76bc5271ac9a\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-3733308c-b6f6-49a1-903a-76bc5271ac9a')\"\n","            title=\"Suggest charts\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-3733308c-b6f6-49a1-903a-76bc5271ac9a button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","\n","  <div id=\"id_86919f09-5938-4dcc-bef2-3eb5b65a3d98\">\n","    <style>\n","      .colab-df-generate {\n","        background-color: #E8F0FE;\n","        border: none;\n","        border-radius: 50%;\n","        cursor: pointer;\n","        display: none;\n","        fill: #1967D2;\n","        height: 32px;\n","        padding: 0 0 0 0;\n","        width: 32px;\n","      }\n","\n","      .colab-df-generate:hover {\n","        background-color: #E2EBFA;\n","        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","        fill: #174EA6;\n","      }\n","\n","      [theme=dark] .colab-df-generate {\n","        background-color: #3B4455;\n","        fill: #D2E3FC;\n","      }\n","\n","      [theme=dark] .colab-df-generate:hover {\n","        background-color: #434B5C;\n","        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","        fill: #FFFFFF;\n","      }\n","    </style>\n","    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df')\"\n","            title=\"Generate code using this dataframe.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n","  </svg>\n","    </button>\n","    <script>\n","      (() => {\n","      const buttonEl =\n","        document.querySelector('#id_86919f09-5938-4dcc-bef2-3eb5b65a3d98 button.colab-df-generate');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      buttonEl.onclick = () => {\n","        google.colab.notebook.generateWithVariable('df');\n","      }\n","      })();\n","    </script>\n","  </div>\n","\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","variable_name":"df","summary":"{\n  \"name\": \"df\",\n  \"rows\": 1299,\n  \"fields\": [\n    {\n      \"column\": \"Unnamed: 0\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 139,\n        \"min\": 0,\n        \"max\": 551,\n        \"num_unique_values\": 552,\n        \"samples\": [\n          548,\n          81,\n          140\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"age\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 89,\n        \"samples\": [\n          \"86.0\",\n          \"75\",\n          \"54.0\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"gender\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"female\",\n          \"male\",\n          \"other\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"mmse\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 6.5929389230381386,\n        \"min\": 1.0,\n        \"max\": 31.0,\n        \"num_unique_values\": 28,\n        \"samples\": [\n          20.0,\n          1.0,\n          11.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"count_unintelligible\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 0,\n        \"max\": 12,\n        \"num_unique_values\": 11,\n        \"samples\": [\n          6,\n          0,\n          7\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"count_trailing\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 0,\n        \"max\": 13,\n        \"num_unique_values\": 11,\n        \"samples\": [\n          4,\n          0,\n          9\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"count_repetitions\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 0,\n        \"max\": 22,\n        \"num_unique_values\": 17,\n        \"samples\": [\n          2,\n          0,\n          5\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"category\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"data\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1299,\n        \"samples\": [\n          \" paperq . oh \\u2021 a sentence . I thought you just wanted another word . you need a pencil to write with . treeq ? we've got alotof apples on our tree and they're all wormy . that's the truth . that's a true one . it's a shame we waited for them to come out and now they're all bad .  what do you mean  oh \\u2021 the child the child fell and hadta go to the hospital . dress warm, it's a cold winter . the doctor sit me in a chair ? open the bureau drawer . \",\n          \"  w\\u025b\\u014bg\\u0259zu . bananas . spaghetti .  melons .  nuts .  meat .  fish .  turkey .  chicken .  okay \\u2021 names ? no no names   we're eating now ? sl .  Sam . oh \\u2021 okay okay \\u2021 sorry . sl .  sl .  spaghetti .    every any word . sunq .  wind . sl .  stole . \"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"pauses\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 4,\n        \"min\": 0,\n        \"max\": 28,\n        \"num_unique_values\": 24,\n        \"samples\": [\n          8,\n          17\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Transcripts_cleaned\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1298,\n        \"samples\": [\n          \" george moved in with his granddaughter . i think . hm that's about all i think . that's not alot though \\u201e is it no \\u2021 hunhunh \\u2021 i can't . no \\u2021 i don't think so \\u201e honey . oh \\u2021 god help me . is that the one about that's the one about the man and the little girl they took a walk didn't they hm i that's all i can remember \\u201e honey . i gotta have a clue on that . i don't know . oh \\u2021 it was it was a grandfather and a little girl \\u201e wasn't it or was it maybe it's wasn't . i don't know . didn't they walk too far or something in the winter i don't know \\u201e honey . snow i don't know . so she wouldn't fall \\u201e i guess . i don't know . wasn't listening to that one \\u201e was i \\u201e huh too much traffic . couldn't cross the street . \",\n          \" dog . a cat . a hog . a horse . a sheep . a goat . an elephant . a lion . a tiger . a goose . snake . a rhinoceros . a hippopotamus . raccoon . possum . a squirrel . a chipmunk . alligator . rhinoceros . no \\u2021 we're gonna to use the letter fl . mhm fun . finance . fork . folly . frustration . future . frog . fantastic . firm . follow . falling . fog . fortune . freedom . forecast . frankenstein . funny . \"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Transcripts_stem\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1298,\n        \"samples\": [\n          \"georg move in with his granddaught . i think . hm that about all i think . that not alot though \\u201e is it no \\u2021 hunhunh \\u2021 i can't . no \\u2021 i don't think so \\u201e honey . oh \\u2021 god help me . is that the one about that the one about the man and the littl girl they took a walk didn't they hm i that all i can rememb \\u201e honey . i gotta have a clue on that . i don't know . oh \\u2021 it was it was a grandfath and a littl girl \\u201e wasn't it or was it mayb it wasn't . i don't know . didn't they walk too far or someth in the winter i don't know \\u201e honey . snow i don't know . so she wouldn't fall \\u201e i guess . i don't know . wasn't listen to that one \\u201e was i \\u201e huh too much traffic . couldn't cross the street .\",\n          \"dog . a cat . a hog . a hors . a sheep . a goat . an eleph . a lion . a tiger . a goos . snake . a rhinocero . a hippopotamus . raccoon . possum . a squirrel . a chipmunk . allig . rhinocero . no \\u2021 we'r gonna to use the letter fl . mhm fun . financ . fork . folli . frustrat . futur . frog . fantast . firm . follow . fall . fog . fortun . freedom . forecast . frankenstein . funni .\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Transcripts_lem\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1298,\n        \"samples\": [\n          \"george moved in with his granddaughter . i think . hm that 's about all i think . that 's not alot though \\u201e is it no \\u2021 hunhunh \\u2021 i ca n't . no \\u2021 i do n't think so \\u201e honey . oh \\u2021 god help me . is that the one about that 's the one about the man and the little girl they took a walk did n't they hm i that 's all i can remember \\u201e honey . i got ta have a clue on that . i do n't know . oh \\u2021 it wa it wa a grandfather and a little girl \\u201e wa n't it or wa it maybe it 's wa n't . i do n't know . did n't they walk too far or something in the winter i do n't know \\u201e honey . snow i do n't know . so she would n't fall \\u201e i guess . i do n't know . wa n't listening to that one \\u201e wa i \\u201e huh too much traffic . could n't cross the street .\",\n          \"dog . a cat . a hog . a horse . a sheep . a goat . an elephant . a lion . a tiger . a goose . snake . a rhinoceros . a hippopotamus . raccoon . possum . a squirrel . a chipmunk . alligator . rhinoceros . no \\u2021 we 're gon na to use the letter fl . mhm fun . finance . fork . folly . frustration . future . frog . fantastic . firm . follow . falling . fog . fortune . freedom . forecast . frankenstein . funny .\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"}},"metadata":{},"execution_count":384}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yCRiYOoRderM","outputId":"56331f8e-df20-4b26-af23-ff8c6615280d","executionInfo":{"status":"ok","timestamp":1711885922013,"user_tz":-330,"elapsed":11040,"user":{"displayName":"Kaushik Gauni","userId":"05737776589038746840"}}},"source":["!pip install transformers"],"execution_count":385,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.38.2)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.13.3)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.20.3)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.25.2)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.0)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.12.25)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n","Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.15.2)\n","Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.2)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.2)\n","Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (2023.6.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (4.10.0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.6)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.2.2)\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"db5GAUTDeLmE","outputId":"2e3cbd0d-4f14-4303-d7f8-6b56ab3b7d88","executionInfo":{"status":"ok","timestamp":1711885929381,"user_tz":-330,"elapsed":7373,"user":{"displayName":"Kaushik Gauni","userId":"05737776589038746840"}}},"source":["!pip install pytorch-pretrained-bert"],"execution_count":386,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: pytorch-pretrained-bert in /usr/local/lib/python3.10/dist-packages (0.6.2)\n","Requirement already satisfied: torch>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from pytorch-pretrained-bert) (2.2.1+cu121)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from pytorch-pretrained-bert) (1.25.2)\n","Requirement already satisfied: boto3 in /usr/local/lib/python3.10/dist-packages (from pytorch-pretrained-bert) (1.34.74)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from pytorch-pretrained-bert) (2.31.0)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from pytorch-pretrained-bert) (4.66.2)\n","Requirement already satisfied: regex in /usr/local/lib/python3.10/dist-packages (from pytorch-pretrained-bert) (2023.12.25)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=0.4.1->pytorch-pretrained-bert) (3.13.3)\n","Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=0.4.1->pytorch-pretrained-bert) (4.10.0)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=0.4.1->pytorch-pretrained-bert) (1.12)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=0.4.1->pytorch-pretrained-bert) (3.2.1)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=0.4.1->pytorch-pretrained-bert) (3.1.3)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=0.4.1->pytorch-pretrained-bert) (2023.6.0)\n","Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=0.4.1->pytorch-pretrained-bert) (12.1.105)\n","Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=0.4.1->pytorch-pretrained-bert) (12.1.105)\n","Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=0.4.1->pytorch-pretrained-bert) (12.1.105)\n","Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch>=0.4.1->pytorch-pretrained-bert) (8.9.2.26)\n","Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=0.4.1->pytorch-pretrained-bert) (12.1.3.1)\n","Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch>=0.4.1->pytorch-pretrained-bert) (11.0.2.54)\n","Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch>=0.4.1->pytorch-pretrained-bert) (10.3.2.106)\n","Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch>=0.4.1->pytorch-pretrained-bert) (11.4.5.107)\n","Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch>=0.4.1->pytorch-pretrained-bert) (12.1.0.106)\n","Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /usr/local/lib/python3.10/dist-packages (from torch>=0.4.1->pytorch-pretrained-bert) (2.19.3)\n","Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=0.4.1->pytorch-pretrained-bert) (12.1.105)\n","Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch>=0.4.1->pytorch-pretrained-bert) (2.2.0)\n","Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=0.4.1->pytorch-pretrained-bert) (12.4.99)\n","Requirement already satisfied: botocore<1.35.0,>=1.34.74 in /usr/local/lib/python3.10/dist-packages (from boto3->pytorch-pretrained-bert) (1.34.74)\n","Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from boto3->pytorch-pretrained-bert) (1.0.1)\n","Requirement already satisfied: s3transfer<0.11.0,>=0.10.0 in /usr/local/lib/python3.10/dist-packages (from boto3->pytorch-pretrained-bert) (0.10.1)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->pytorch-pretrained-bert) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->pytorch-pretrained-bert) (3.6)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->pytorch-pretrained-bert) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->pytorch-pretrained-bert) (2024.2.2)\n","Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.10/dist-packages (from botocore<1.35.0,>=1.34.74->boto3->pytorch-pretrained-bert) (2.8.2)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=0.4.1->pytorch-pretrained-bert) (2.1.5)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=0.4.1->pytorch-pretrained-bert) (1.3.0)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.35.0,>=1.34.74->boto3->pytorch-pretrained-bert) (1.16.0)\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BMAFT4ZU6xdE","outputId":"d744d267-fa49-4696-9a17-218c211dec03","executionInfo":{"status":"ok","timestamp":1711885930013,"user_tz":-330,"elapsed":640,"user":{"displayName":"Kaushik Gauni","userId":"05737776589038746840"}}},"source":["from transformers import BertTokenizer\n","\n","print('Loading BERT tokenizer...')\n","tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)"],"execution_count":387,"outputs":[{"output_type":"stream","name":"stdout","text":["Loading BERT tokenizer...\n"]}]},{"cell_type":"code","metadata":{"id":"M8slQpK060B9","executionInfo":{"status":"ok","timestamp":1711885930013,"user_tz":-330,"elapsed":9,"user":{"displayName":"Kaushik Gauni","userId":"05737776589038746840"}}},"source":["sentences = df['Transcripts_lem'].values\n","labels = df.category.values"],"execution_count":388,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VyOC0K6d62hu","outputId":"70a70c89-077a-4598-915b-c1f88f479869","executionInfo":{"status":"ok","timestamp":1711885932601,"user_tz":-330,"elapsed":2595,"user":{"displayName":"Kaushik Gauni","userId":"05737776589038746840"}}},"source":["max_len = 0\n","\n","for sent in sentences:\n","    input_ids = tokenizer.encode(sent, add_special_tokens=True,max_length=256)\n","    max_len = max(max_len, len(input_ids))\n","\n","print('Max sentence length: ', max_len)"],"execution_count":389,"outputs":[{"output_type":"stream","name":"stderr","text":["Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"]},{"output_type":"stream","name":"stdout","text":["Max sentence length:  256\n"]}]},{"cell_type":"code","metadata":{"id":"mER5ov2B66bQ","executionInfo":{"status":"ok","timestamp":1711885932601,"user_tz":-330,"elapsed":10,"user":{"displayName":"Kaushik Gauni","userId":"05737776589038746840"}}},"source":["import tensorflow as tf\n","import torch"],"execution_count":390,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7jAtPUK868tb","outputId":"7b5a13e9-9bd2-4cd2-c545-3efbdae59f1b","executionInfo":{"status":"ok","timestamp":1711885936401,"user_tz":-330,"elapsed":3809,"user":{"displayName":"Kaushik Gauni","userId":"05737776589038746840"}}},"source":["input_ids = []\n","attention_masks = []\n","\n","for sent in sentences:\n","    encoded_dict = tokenizer.encode_plus(\n","                        sent,\n","                        add_special_tokens = True,\n","                        max_length = 256,\n","                        pad_to_max_length = True,\n","                        return_attention_mask = True,\n","                        return_tensors = 'pt',\n","                   )\n","    input_ids.append(encoded_dict['input_ids'])\n","    attention_masks.append(encoded_dict['attention_mask'])\n","\n","input_ids = torch.cat(input_ids, dim=0)\n","attention_masks = torch.cat(attention_masks, dim=0)\n","labels = torch.tensor(labels)\n","\n","print('Original: ', sentences[0])\n","print('Token IDs:', input_ids[0])"],"execution_count":391,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2645: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["Original:  the scene is in the in the kitchen . the mother is wiping dish and the water is running on the floor . a child is trying to get a boy is trying to get cooky outta out a jar and he 's about to tip over on a stool . the little girl is reacting to his falling . it seems to be summer out . the window is open . the curtain are blowing . it must be a gentle breeze . there 's grass outside in the garden . mother 's finished certain of the the dish . kitchen 's very tidy . the mother seems to have nothing in the house to eat except cooky in the cookie jar . the child look to be almost about the same size . perhaps they 're twin . they 're dressed for summer warm weather . you want more the mother 's in a short sleeve dress . i 'll hafta say it 's warm .\n","Token IDs: tensor([  101,  1996,  3496,  2003,  1999,  1996,  1999,  1996,  3829,  1012,\n","         1996,  2388,  2003, 14612,  9841,  1998,  1996,  2300,  2003,  2770,\n","         2006,  1996,  2723,  1012,  1037,  2775,  2003,  2667,  2000,  2131,\n","         1037,  2879,  2003,  2667,  2000,  2131,  5660,  2100, 24955,  2041,\n","         1037, 15723,  1998,  2002,  1005,  1055,  2055,  2000,  5955,  2058,\n","         2006,  1037, 14708,  1012,  1996,  2210,  2611,  2003, 24868,  2000,\n","         2010,  4634,  1012,  2009,  3849,  2000,  2022,  2621,  2041,  1012,\n","         1996,  3332,  2003,  2330,  1012,  1996, 11002,  2024, 11221,  1012,\n","         2009,  2442,  2022,  1037,  7132,  9478,  1012,  2045,  1005,  1055,\n","         5568,  2648,  1999,  1996,  3871,  1012,  2388,  1005,  1055,  2736,\n","         3056,  1997,  1996,  1996,  9841,  1012,  3829,  1005,  1055,  2200,\n","        29369,  1012,  1996,  2388,  3849,  2000,  2031,  2498,  1999,  1996,\n","         2160,  2000,  4521,  3272,  5660,  2100,  1999,  1996, 17387, 15723,\n","         1012,  1996,  2775,  2298,  2000,  2022,  2471,  2055,  1996,  2168,\n","         2946,  1012,  3383,  2027,  1005,  2128,  5519,  1012,  2027,  1005,\n","         2128,  5102,  2005,  2621,  4010,  4633,  1012,  2017,  2215,  2062,\n","         1996,  2388,  1005,  1055,  1999,  1037,  2460, 10353,  4377,  1012,\n","         1045,  1005,  2222,  5292,  6199,  2050,  2360,  2009,  1005,  1055,\n","         4010,  1012,   102,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0])\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KBR8AwVNOQCw","outputId":"d115d21f-3512-470e-a303-08e5d79def29","executionInfo":{"status":"ok","timestamp":1711885936401,"user_tz":-330,"elapsed":15,"user":{"displayName":"Kaushik Gauni","userId":"05737776589038746840"}}},"source":["print(input_ids.shape)\n","print(attention_masks.shape)\n","print(labels.shape)"],"execution_count":392,"outputs":[{"output_type":"stream","name":"stdout","text":["torch.Size([1299, 256])\n","torch.Size([1299, 256])\n","torch.Size([1299])\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vEzpBJRW7J0_","outputId":"d3fceef4-2489-498d-ce95-86de057d8fa3","executionInfo":{"status":"ok","timestamp":1711885936402,"user_tz":-330,"elapsed":11,"user":{"displayName":"Kaushik Gauni","userId":"05737776589038746840"}}},"source":["from torch.utils.data import TensorDataset, random_split\n","\n","dataset = TensorDataset(input_ids, attention_masks, labels)\n","\n","train_size = int(0.8 * len(dataset))\n","val_size = int(0.1 * len(dataset))\n","test_size = len(dataset) - train_size - val_size\n","\n","train_dataset, val_dataset, test_dataset = random_split(dataset, [train_size, val_size,test_size])\n","\n","print('{:>5,} training samples'.format(train_size))\n","print('{:>5,} validation samples'.format(val_size))\n","print('{:>5,} test samples'.format(test_size))"],"execution_count":393,"outputs":[{"output_type":"stream","name":"stdout","text":["1,039 training samples\n","  129 validation samples\n","  131 test samples\n"]}]},{"cell_type":"code","metadata":{"id":"cIAl5MRo7NJz","executionInfo":{"status":"ok","timestamp":1711885936402,"user_tz":-330,"elapsed":7,"user":{"displayName":"Kaushik Gauni","userId":"05737776589038746840"}}},"source":["from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n","\n","batch_size = 32\n","\n","train_dataloader = DataLoader(\n","            train_dataset,\n","            sampler = RandomSampler(train_dataset),\n","            batch_size = batch_size\n","        )\n","\n","validation_dataloader = DataLoader(\n","            val_dataset,\n","            sampler = SequentialSampler(val_dataset),\n","            batch_size = batch_size\n","        )\n","test_dataloader = DataLoader(\n","            test_dataset,\n","            sampler = SequentialSampler(test_dataset),\n","            batch_size = batch_size\n","        )"],"execution_count":394,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":428},"id":"7WR5JD7H7TSX","outputId":"e7071ed2-99c7-4c73-d024-5b484943ad77","executionInfo":{"status":"error","timestamp":1711885937119,"user_tz":-330,"elapsed":723,"user":{"displayName":"Kaushik Gauni","userId":"05737776589038746840"}}},"source":["from transformers import BertForSequenceClassification, AdamW, BertConfig\n","\n","model = BertForSequenceClassification.from_pretrained(\n","    \"bert-base-uncased\",\n","    num_labels = 2,\n","    output_attentions = False,\n","    output_hidden_states = False,\n",")\n","\n","# Tell pytorch to run this model on the GPU.\n","model.cuda()"],"execution_count":395,"outputs":[{"output_type":"stream","name":"stderr","text":["Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"error","ename":"OutOfMemoryError","evalue":"CUDA out of memory. Tried to allocate 90.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 37.06 MiB is free. Process 3950 has 14.71 GiB memory in use. Of the allocated memory 13.95 GiB is allocated by PyTorch, and 642.09 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)","\u001b[0;32m<ipython-input-395-5a269eb2b238>\u001b[0m in \u001b[0;36m<cell line: 11>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m# Tell pytorch to run this model on the GPU.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/modeling_utils.py\u001b[0m in \u001b[0;36mcuda\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2526\u001b[0m             )\n\u001b[1;32m   2527\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2528\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2529\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2530\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mwraps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mcuda\u001b[0;34m(self, device)\u001b[0m\n\u001b[1;32m    909\u001b[0m             \u001b[0mModule\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    910\u001b[0m         \"\"\"\n\u001b[0;32m--> 911\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    912\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    913\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mipu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    800\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrecurse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    801\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 802\u001b[0;31m                 \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    803\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    804\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    800\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrecurse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    801\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 802\u001b[0;31m                 \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    803\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    804\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    800\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrecurse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    801\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 802\u001b[0;31m                 \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    803\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    804\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    823\u001b[0m             \u001b[0;31m# `with torch.no_grad():`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    824\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 825\u001b[0;31m                 \u001b[0mparam_applied\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    826\u001b[0m             \u001b[0mshould_use_set_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mshould_use_set_data\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    909\u001b[0m             \u001b[0mModule\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    910\u001b[0m         \"\"\"\n\u001b[0;32m--> 911\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    912\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    913\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mipu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 90.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 37.06 MiB is free. Process 3950 has 14.71 GiB memory in use. Of the allocated memory 13.95 GiB is allocated by PyTorch, and 642.09 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"]}]},{"cell_type":"code","metadata":{"id":"DR6SV5Sp-xbu","executionInfo":{"status":"aborted","timestamp":1711885937119,"user_tz":-330,"elapsed":14,"user":{"displayName":"Kaushik Gauni","userId":"05737776589038746840"}}},"source":["params = list(model.named_parameters())\n","\n","print('The BERT model has {:} different named parameters.\\n'.format(len(params)))\n","\n","print('==== Embedding Layer ====\\n')\n","\n","for p in params[0:5]:\n","    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n","\n","print('\\n==== First Transformer ====\\n')\n","\n","for p in params[5:21]:\n","    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n","\n","print('\\n==== Output Layer ====\\n')\n","\n","for p in params[-4:]:\n","    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"uA07gq5B-2uj","executionInfo":{"status":"aborted","timestamp":1711885937120,"user_tz":-330,"elapsed":14,"user":{"displayName":"Kaushik Gauni","userId":"05737776589038746840"}}},"source":["optimizer = AdamW(model.parameters(),\n","                  lr = 2e-5,\n","                  eps = 1e-8\n","                )"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZtsD0xzn-6mk","executionInfo":{"status":"aborted","timestamp":1711885937120,"user_tz":-330,"elapsed":14,"user":{"displayName":"Kaushik Gauni","userId":"05737776589038746840"}}},"source":["from transformers import get_linear_schedule_with_warmup\n","\n","epochs = 5\n","\n","total_steps = len(train_dataloader) * epochs\n","\n","# Create the learning rate scheduler.\n","scheduler = get_linear_schedule_with_warmup(optimizer,\n","                                            num_warmup_steps = 0, # Default value in run_glue.py\n","                                            num_training_steps = total_steps)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"eNSzS5gT_H3W","executionInfo":{"status":"aborted","timestamp":1711885937120,"user_tz":-330,"elapsed":14,"user":{"displayName":"Kaushik Gauni","userId":"05737776589038746840"}}},"source":["import numpy as np\n","\n","# Function to calculate the accuracy of our predictions vs labels\n","def flat_accuracy(preds, labels):\n","    pred_flat = np.argmax(preds, axis=1).flatten()\n","    labels_flat = labels.flatten()\n","    return np.sum(pred_flat == labels_flat) / len(labels_flat)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"gTgyYBUc_LFg","executionInfo":{"status":"aborted","timestamp":1711885937121,"user_tz":-330,"elapsed":14,"user":{"displayName":"Kaushik Gauni","userId":"05737776589038746840"}}},"source":["import time\n","import datetime\n","\n","def format_time(elapsed):\n","    '''\n","    Takes a time in seconds and returns a string hh:mm:ss\n","    '''\n","    # Round to the nearest second.\n","    elapsed_rounded = int(round((elapsed)))\n","\n","    # Format as hh:mm:ss\n","    return str(datetime.timedelta(seconds=elapsed_rounded))\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"JZ7zOpV2_OEM","executionInfo":{"status":"aborted","timestamp":1711885937121,"user_tz":-330,"elapsed":14,"user":{"displayName":"Kaushik Gauni","userId":"05737776589038746840"}}},"source":["device = torch.device(\"cuda\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"MwbFQJ35_XZA","executionInfo":{"status":"aborted","timestamp":1711885937121,"user_tz":-330,"elapsed":14,"user":{"displayName":"Kaushik Gauni","userId":"05737776589038746840"}}},"source":["import random\n","import numpy as np\n","\n","seed_val = 42\n","\n","random.seed(seed_val)\n","np.random.seed(seed_val)\n","torch.manual_seed(seed_val)\n","torch.cuda.manual_seed_all(seed_val)\n","\n","\n","training_stats = []\n","total_t0 = time.time()\n","\n","# For each epoch...\n","for epoch_i in range(0, epochs):\n","\n","    # ========================================\n","    #               Training\n","    # ========================================\n","\n","    print(\"\")\n","    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n","    print('Training...')\n","\n","    t0 = time.time()\n","    total_train_loss = 0\n","\n","    # Put the model into training mode.\n","    model.train()\n","\n","    # For each batch of training data...\n","    for step, batch in enumerate(train_dataloader):\n","\n","        # Progress update every 40 batches.\n","        if step % 40 == 0 and not step == 0:\n","            elapsed = format_time(time.time() - t0)\n","            print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n","\n","        # Unpacking this training batch from our dataloader.\n","        # `batch` contains three pytorch tensors:\n","        #   [0]: input ids\n","        #   [1]: attention masks\n","        #   [2]: labels\n","        b_input_ids = batch[0].to(device)\n","        b_input_mask = batch[1].to(device)\n","        b_labels = batch[2].to(device)\n","\n","        model.zero_grad()\n","\n","        # Performing a forward pass (evaluate the model on this training batch).\n","        outputs = model(b_input_ids,\n","                             token_type_ids=None,\n","                             attention_mask=b_input_mask,\n","                             labels=b_labels)\n","        loss=outputs[0]\n","\n","        # Accumulating the training loss over all of the batches so that we can\n","        total_train_loss += loss.item()\n","\n","        # Performing a backward pass to calculate the gradients.\n","        loss.backward()\n","\n","        # Clipping the norm of the gradients to 1.0.\n","        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n","\n","        optimizer.step()\n","\n","        # Updating the learning rate.\n","        scheduler.step()\n","\n","    # Calculating the average loss over all of the batches.\n","    avg_train_loss = total_train_loss / len(train_dataloader)\n","\n","    # Measuring how long this epoch took.\n","    training_time = format_time(time.time() - t0)\n","\n","    print(\"\")\n","    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n","    print(\"  Training epoch took: {:}\".format(training_time))\n","\n","    # ========================================\n","    #               Validation\n","    # ========================================\n","\n","    print(\"\")\n","    print(\"Running Validation...\")\n","\n","    t0 = time.time()\n","\n","    # Put the model in evaluation mode\n","    model.eval()\n","\n","    total_eval_accuracy = 0\n","    total_eval_loss = 0\n","    nb_eval_steps = 0\n","\n","    for batch in validation_dataloader:\n","\n","        b_input_ids = batch[0].to(device)\n","        b_input_mask = batch[1].to(device)\n","        b_labels = batch[2].to(device)\n","\n","        with torch.no_grad():\n","\n","            # Forward pass, calculating logit predictions.\n","            outputs = model(b_input_ids,\n","                                   token_type_ids=None,\n","                                   attention_mask=b_input_mask,\n","                                   labels=b_labels)\n","        loss=outputs[0]\n","\n","        # Accumulating the validation loss.\n","        total_eval_loss += loss.item()\n","\n","        logits=outputs[1]\n","        # Moving logits and labels to CPU\n","        logits = logits.detach().cpu().numpy()\n","        label_ids = b_labels.to('cpu').numpy()\n","\n","        # Calculating the accuracy for this batch of test sentences, and accumulate it over all batches.\n","        total_eval_accuracy += flat_accuracy(logits, label_ids)\n","\n","\n","    # Reporting the final accuracy for this validation run.\n","    avg_val_accuracy = total_eval_accuracy / len(validation_dataloader)\n","    print(\"  Accuracy: {0:.2f}\".format(avg_val_accuracy))\n","\n","    # Calculating the average loss over all of the batches.\n","    avg_val_loss = total_eval_loss / len(validation_dataloader)\n","\n","    # Measuring how long the validation run took.\n","    validation_time = format_time(time.time() - t0)\n","\n","    print(\"  Validation Loss: {0:.2f}\".format(avg_val_loss))\n","    print(\"  Validation took: {:}\".format(validation_time))\n","\n","    # Recording all statistics from this epoch.\n","    training_stats.append(\n","        {\n","            'epoch': epoch_i + 1,\n","            'Training Loss': avg_train_loss,\n","            'Valid. Loss': avg_val_loss,\n","            'Valid. Accur.': avg_val_accuracy,\n","            'Training Time': training_time,\n","            'Validation Time': validation_time\n","        }\n","    )\n","\n","print(\"\")\n","print(\"Training complete!\")\n","\n","print(\"Total training took {:} (h:mm:ss)\".format(format_time(time.time()-total_t0)))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"p3hjBE3WcS4K","executionInfo":{"status":"aborted","timestamp":1711885937121,"user_tz":-330,"elapsed":14,"user":{"displayName":"Kaushik Gauni","userId":"05737776589038746840"}}},"source":["import pandas as pd\n","\n","pd.set_option('display.precision', 6)\n","\n","df_stats = pd.DataFrame(data=training_stats)\n","\n","df_stats = df_stats.set_index('epoch')\n","\n","df_stats"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"niCVHea_cay0","executionInfo":{"status":"aborted","timestamp":1711885937121,"user_tz":-330,"elapsed":14,"user":{"displayName":"Kaushik Gauni","userId":"05737776589038746840"}}},"source":["import matplotlib.pyplot as plt\n","%matplotlib inline\n","\n","import seaborn as sns\n","\n","sns.set(style='ticks')\n","\n","sns.set(font_scale=1.5)\n","plt.rcParams[\"figure.figsize\"] = (12,6)\n","\n","plt.plot(df_stats['Training Loss'], 'b', label=\"Training\")\n","plt.plot(df_stats['Valid. Loss'], 'g', label=\"Validation\")\n","\n","plt.title(\"Training & Validation Loss\")\n","plt.xlabel(\"Epoch\")\n","plt.ylabel(\"Loss\")\n","plt.legend()\n","plt.xticks([1, 2, 3, 4])\n","\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"hJc5Up6pclXB","executionInfo":{"status":"aborted","timestamp":1711885937122,"user_tz":-330,"elapsed":14,"user":{"displayName":"Kaushik Gauni","userId":"05737776589038746840"}}},"source":["import matplotlib.pyplot as plt\n","%matplotlib inline\n","\n","import seaborn as sns\n","\n","sns.set(style='darkgrid')\n","\n","sns.set(font_scale=1.5)\n","plt.rcParams[\"figure.figsize\"] = (12,6)\n","\n","plt.plot(df_stats['Valid. Accur.'], 'b', label=\"Validation_acc\")\n","plt.plot(df_stats['Valid. Loss'], 'g', label=\"Validation_loss\")\n","\n","plt.title(\"Validation accuracy & Validation Loss\")\n","plt.xlabel(\"Epoch\")\n","plt.ylabel(\"Loss\")\n","plt.legend()\n","plt.xticks([1, 2, 3, 4])\n","\n","plt.show()\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"unF57nMycr9S","executionInfo":{"status":"aborted","timestamp":1711885937122,"user_tz":-330,"elapsed":14,"user":{"displayName":"Kaushik Gauni","userId":"05737776589038746840"}}},"source":["import torch.nn.functional as F\n","# Put model in evaluation mode\n","model.eval()\n","\n","predictions , true_labels = [], []\n","prediction_probs = []\n","for batch in test_dataloader:\n","  batch = tuple(t.to(device) for t in batch)\n","\n","  b_input_ids, b_input_mask, b_labels = batch\n","\n","  with torch.no_grad():\n","      outputs = model(b_input_ids, token_type_ids=None,\n","                      attention_mask=b_input_mask)\n","\n","  _, preds = torch.max(outputs[0], dim=1)\n","  logits = outputs[0]\n","  predictions.extend(preds)\n","  prediction_probs.extend(outputs[0])\n","\n","  logits = logits.detach().cpu().numpy()\n","\n","  #predictions.append(logits)\n","  true_labels.extend(b_labels)\n","predictions = torch.stack(predictions).cpu()\n","prediction_probs = torch.stack(prediction_probs).cpu()\n","true_labels = torch.stack(true_labels).cpu()\n","\n","print('    DONE.')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"K-Fp9pnUcv7O","executionInfo":{"status":"aborted","timestamp":1711885937122,"user_tz":-330,"elapsed":14,"user":{"displayName":"Kaushik Gauni","userId":"05737776589038746840"}}},"source":["true_labels"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"l_sNkwL2c0x_","executionInfo":{"status":"aborted","timestamp":1711885937122,"user_tz":-330,"elapsed":14,"user":{"displayName":"Kaushik Gauni","userId":"05737776589038746840"}}},"source":["from sklearn.metrics import confusion_matrix\n","from sklearn.metrics import accuracy_score, log_loss\n","from sklearn.metrics import precision_recall_fscore_support, classification_report\n","from sklearn.metrics import roc_curve , roc_auc_score, auc\n","\n","def evaluate_roc(probs, y_true):\n","    preds = probs[:, 1]\n","    fpr, tpr, threshold = roc_curve(y_true, preds)\n","    roc_auc = auc(fpr, tpr)\n","    print(f'AUC: {roc_auc:.4f}')\n","\n","    y_pred = np.where(preds >= 0.5, 1, 0)\n","    accuracy = accuracy_score(y_true, y_pred)\n","    print(f'Accuracy: {accuracy*100:.2f}%')\n","\n","\n","    plt.title('Receiver Operating Characteristic')\n","    plt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)\n","    plt.legend(loc = 'lower right')\n","    plt.plot([0, 1], [0, 1],'r--')\n","    plt.xlim([0, 1])\n","    plt.ylim([0, 1])\n","    plt.ylabel('True Positive Rate')\n","    plt.xlabel('False Positive Rate')\n","    plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"TkjjRDtvc4K9","executionInfo":{"status":"aborted","timestamp":1711885937122,"user_tz":-330,"elapsed":14,"user":{"displayName":"Kaushik Gauni","userId":"05737776589038746840"}}},"source":["evaluate_roc(prediction_probs , true_labels)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"PGxCE6oDggNv","executionInfo":{"status":"aborted","timestamp":1711885937123,"user_tz":-330,"elapsed":14,"user":{"displayName":"Kaushik Gauni","userId":"05737776589038746840"}}},"source":["from sklearn.metrics import confusion_matrix\n","from sklearn.metrics import accuracy_score, log_loss\n","from sklearn.metrics import precision_recall_fscore_support, classification_report\n","from sklearn.metrics import roc_curve , roc_auc_score\n","\n","\n","labels = [0, 1]\n","print(accuracy_score(true_labels, predictions))\n","print(confusion_matrix(true_labels, predictions))\n","#print(precision_recall_fscore_support(true_labels, predictions, average=None, labels= labels))\n","print(classification_report(true_labels, predictions))"],"execution_count":null,"outputs":[]}]}